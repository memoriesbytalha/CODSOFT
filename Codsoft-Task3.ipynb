{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "\n",
        "#I used Huggingface to get pretrained model integrating into this code through transformers.\n",
        "# Thank you codsoft\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "max_length = 16\n",
        "num_beams = 4\n",
        "gen_arguments = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
        "\n",
        "def captions(image_paths):\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "        i_image = Image.open(image_path)\n",
        "        if i_image.mode != \"RGB\":\n",
        "            i_image = i_image.convert(mode=\"RGB\")\n",
        "\n",
        "        images.append(i_image)\n",
        "\n",
        "    pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
        "    pixel_values = pixel_values.to(device)\n",
        "\n",
        "    output_ids = model.generate(pixel_values, **gen_arguments)\n",
        "\n",
        "    predictions = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "    predictions = [pred.strip() for pred in predictions]\n",
        "    return predictions\n",
        "\n",
        "captions([\"download.jpg\"])\n"
      ],
      "metadata": {
        "id": "MoRx1OMqLfTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981aa1db-76ea-41e1-8870-a96c142fd566"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a man in a suit talking on a cell phone']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}
